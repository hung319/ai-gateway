import os
from typing import Optional
from sqlmodel import Session, select
from litellm import Router
from app.models import Provider
from app.config import REDIS_URL, ENABLE_CACHE, LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY

class AIEngine:
    def __init__(self):
        self.router: Optional[Router] = None
        
    def initialize(self, session: Session):
        print("üîÑ [Engine] Initializing...")
        
        # 1. Langfuse Config
        if LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY:
            os.environ["LANGFUSE_PUBLIC_KEY"] = LANGFUSE_PUBLIC_KEY
            os.environ["LANGFUSE_SECRET_KEY"] = LANGFUSE_SECRET_KEY
            from litellm import success_callback, failure_callback
            if "langfuse" not in success_callback: success_callback.append("langfuse")
            if "langfuse" not in failure_callback: failure_callback.append("langfuse")
            print("‚úÖ [Engine] Langfuse Logging Active")

        # 2. Load Providers -> Router
        providers = session.exec(select(Provider)).all()
        model_list = []
        
        for p in providers:
            # --- [FIX QUAN TR·ªåNG] ---
            # Lu√¥n ƒë·ªãnh d·∫°ng model l√† "provider/name" ƒë·ªÉ LiteLLM kh√¥ng b·ªã l·ªói
            # v·ªõi c√°c model custom (v√≠ d·ª•: duckai, local-model...)
            
            # N·∫øu l√† OpenAI standard (Custom URL ho·∫∑c Official)
            if p.provider_type == "openai":
                # √âp bu·ªôc format: openai/t√™n_alias
                # ƒêi·ªÅu n√†y b√°o cho LiteLLM bi·∫øt: "D√πng giao th·ª©c OpenAI ƒë·ªÉ g·ªçi model n√†y"
                litellm_model_id = f"openai/{p.name}"
            else:
                # C√°c lo·∫°i kh√°c (gemini/t√™n, openrouter/t√™n...)
                litellm_model_id = f"{p.provider_type}/{p.name}"

            deployment = {
                "model_name": p.name, # Alias d√πng ƒë·ªÉ routing
                "litellm_params": {
                    "model": litellm_model_id,
                    "api_key": p.api_key,
                }
            }
            
            if p.base_url:
                deployment["litellm_params"]["api_base"] = p.base_url
            
            model_list.append(deployment)

        # 3. Init Router
        if not model_list:
            print("‚ö†Ô∏è [Engine] No providers found in DB. Waiting for setup...")
            self.router = None
            return

        router_config = {
            "model_list": model_list,
            "set_verbose": False
        }
        
        # Redis Cache
        if REDIS_URL and ENABLE_CACHE:
            router_config["cache_responses"] = True
            os.environ["REDIS_URL"] = REDIS_URL
            print("‚úÖ [Engine] Semantic Caching Enabled")

        try:
            self.router = Router(**router_config)
            print(f"üöÄ [Engine] Router Ready with {len(model_list)} providers")
        except Exception as e:
            print(f"‚ùå [Engine] Router Init Failed: {e}")
            # Kh√¥ng crash app n·∫øu config sai, ƒë·ªÉ admin c√≤n v√†o s·ª≠a ƒë∆∞·ª£c
            self.router = None

    async def reload(self, session: Session):
        self.initialize(session)

ai_engine = AIEngine()
